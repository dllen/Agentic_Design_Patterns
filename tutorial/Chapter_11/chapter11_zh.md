# ç¬¬11ç« ï¼šç›®æ ‡è®¾å®šä¸ç›‘æ§ (Goal Setting and Monitoring)

## æ¨¡å¼æ¦‚è¿°
ç›®æ ‡è®¾å®šä¸ç›‘æ§æ¨¡å¼æ˜¯ä»£ç†ç³»ç»Ÿä¸­çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µï¼Œæ—¨åœ¨æ„å»ºèƒ½å¤Ÿæ ¹æ®é¢„å®šä¹‰ç›®æ ‡è‡ªä¸»ç”Ÿæˆã€æ”¹è¿›å’Œè¯„ä¼°è§£å†³æ–¹æ¡ˆçš„AIä»£ç†ã€‚è¯¥æ¨¡å¼çš„æ ¸å¿ƒæ˜¯åˆ›å»ºä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œå…¶ä¸­ä»£ç†ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼Œæ ¹æ®ç›®æ ‡è¯„ä¼°è¯¥è§£å†³æ–¹æ¡ˆï¼Œç„¶ååœ¨å¿…è¦æ—¶è¿›è¡Œæ”¹è¿›ï¼Œç›´åˆ°æ»¡è¶³ç›®æ ‡ã€‚

è¿™ç§æ¨¡å¼ç‰¹åˆ«é€‚ç”¨äºéœ€è¦é«˜è´¨é‡è¾“å‡ºçš„ä»»åŠ¡ï¼Œå…¶ä¸­è§£å†³æ–¹æ¡ˆéœ€è¦æ»¡è¶³ç‰¹å®šæ ‡å‡†ï¼Œå¦‚ç®€å•æ€§ã€æ­£ç¡®æ€§ã€è¾¹ç¼˜æƒ…å†µå¤„ç†ç­‰ã€‚é€šè¿‡å»ºç«‹åé¦ˆå¾ªç¯ï¼Œä»£ç†å¯ä»¥æŒç»­æ”¹è¿›å…¶è¾“å‡ºï¼Œç›´åˆ°æ»¡è¶³é¢„å®šæ ‡å‡†ã€‚

## æ ¸å¿ƒæ¦‚å¿µ
1. **ç›®æ ‡é©±åŠ¨**ï¼šä»£ç†çš„è¡ŒåŠ¨ç”±æ˜ç¡®çš„ç›®æ ‡é›†æŒ‡å¯¼ã€‚
2. **è¿­ä»£æ”¹è¿›**ï¼šè§£å†³æ–¹æ¡ˆåœ¨å¤šæ¬¡è¿­ä»£ä¸­å¾—åˆ°å®Œå–„ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡ã€‚
3. **è‡ªåŠ¨è¯„ä¼°**ï¼šä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°è§£å†³æ–¹æ¡ˆæ˜¯å¦æ»¡è¶³ç›®æ ‡ã€‚
4. **åé¦ˆå¾ªç¯**ï¼šä»è¯„ä¼°ä¸­è·å–åé¦ˆä»¥æŒ‡å¯¼ä¸‹ä¸€æ¬¡è¿­ä»£ã€‚

## å®é™…åº”ç”¨
Chapter 11ç¬”è®°ä¸­æä¾›äº†ä¸€ä¸ªå…·ä½“ç¤ºä¾‹ï¼šæ„å»ºä¸€ä¸ªAIä»£ç†ï¼Œæ ¹æ®æŒ‡å®šçš„ç”¨ä¾‹å’Œç›®æ ‡ç¼–å†™ä»£ç ã€‚è¯¥ä»£ç†ï¼š
- æ¥å—ç¼–ç é—®é¢˜ï¼ˆç”¨ä¾‹ï¼‰ä½œä¸ºè¾“å…¥
- æ¥å—ç›®æ ‡åˆ—è¡¨ï¼ˆå¦‚"ç®€å•"ã€"ç»è¿‡æµ‹è¯•"ã€"å¤„ç†è¾¹ç¼˜æƒ…å†µ"ï¼‰ä½œä¸ºè¾“å…¥
- ä½¿ç”¨LLMï¼ˆå¦‚GPT-4oï¼‰ç”Ÿæˆå’Œç»†åŒ–Pythonä»£ç ï¼Œç›´åˆ°æ»¡è¶³ç›®æ ‡
- ä¸ºæ£€æŸ¥ç›®æ ‡æ˜¯å¦æ»¡è¶³ï¼Œå‘LLMè¯¢é—®å¹¶å›ç­”Trueæˆ–Falseï¼Œä»è€Œæ›´å®¹æ˜“åœæ­¢è¿­ä»£

## ä»£ç ç¤ºä¾‹
ä»¥ä¸‹æ˜¯ç¬”è®°ä¸­Goal Setting and Monitoringæ¨¡å¼çš„ç®€åŒ–å®ç°ï¼š

```python
import os
import random
import re
from pathlib import Path
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv, find_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
_ = load_dotenv(find_dotenv())
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise EnvironmentError("è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")

# åˆå§‹åŒ–OpenAIæ¨¡å‹
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.3,
    openai_api_key=OPENAI_API_KEY,
)

def generate_prompt(use_case: str, goals: list[str], previous_code: str = "", feedback: str = "") -> str:
    base_prompt = f"""
You are an AI coding agent. Your job is to write Python code based on the following use case:

Use Case: {use_case}

Your goals are:
{chr(10).join(f"- {g.strip()}" for g in goals)}
"""
    if previous_code:
        base_prompt += f"\nPreviously generated code:\n{previous_code}"
    if feedback:
        base_prompt += f"\nFeedback on previous version:\n{feedback}\n"

    base_prompt += "\nPlease return only the revised Python code. Do not include comments or explanations outside the code."
    return base_prompt

def get_code_feedback(code: str, goals: list[str]) -> str:
    feedback_prompt = f"""
You are a Python code reviewer. A code snippet is shown below. Based on the following goals:

{chr(10).join(f"- {g.strip()}" for g in goals)}

Please critique this code and identify if the goals are met. Mention if improvements are needed for clarity, simplicity, correctness, edge case handling, or test coverage.

Code:
{code}
"""
    return llm.invoke(feedback_prompt)

def goals_met(feedback_text: str, goals: list[str]) -> bool:
    """
    ä½¿ç”¨LLMè¯„ä¼°åŸºäºåé¦ˆæ–‡æœ¬æ˜¯å¦æ»¡è¶³ç›®æ ‡
    è¿”å›Trueæˆ–Falseï¼ˆä»LLMè¾“å‡ºè§£æï¼‰
    """
    review_prompt = f"""
You are an AI reviewer.

Here are the goals:
{chr(10).join(f"- {g.strip()}" for g in goals)}

Here is the feedback on the code:
\"\"\"
{feedback_text}
\"\"\"

Based on the feedback above, have the goals been met?

Respond with only one word: True or False.
"""
    response = llm.invoke(review_prompt).content.strip().lower()
    return response == "true"

def run_code_agent(use_case: str, goals_input: str, max_iterations: int = 5) -> str:
    goals = [g.strip() for g in goals_input.split(",")]

    print(f"\nğŸ¯ Use Case: {use_case}")
    print("ğŸ¯ Goals:")
    for g in goals:
        print(f"  - {g}")

    previous_code = ""
    feedback = ""

    for i in range(max_iterations):
        print(f"\n=== ğŸ” Iteration {i + 1} of {max_iterations} ===")
        prompt = generate_prompt(use_case, goals, previous_code, feedback if isinstance(feedback, str) else feedback.content)

        print("ğŸš§ Generating code...")
        code_response = llm.invoke(prompt)
        raw_code = code_response.content.strip()
        # Clean code block if needed
        lines = raw_code.strip().splitlines()
        if lines and lines[0].strip().startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].strip() == "```":
            lines = lines[:-1]
        code = "\n".join(lines).strip()
        print(f"\nğŸ§¾ Generated Code:\n{'-' * 50}\n{code}\n{'-' * 50}")

        print("\nğŸ“¤ Submitting code for feedback review...")
        feedback = get_code_feedback(code, goals)
        feedback_text = feedback.content.strip()
        print(f"\nğŸ“¥ Feedback Received:\n{'-' * 50}\n{feedback_text}\n{'-' * 50}")

        if goals_met(feedback_text, goals):
            print("âœ… LLM confirms goals are met. Stopping iteration.")
            break

        print("ğŸ› ï¸ Goals not fully met. Preparing for next iteration...")
        previous_code = code

    return code
```

## æ€»ç»“
ç›®æ ‡è®¾å®šä¸ç›‘æ§æ¨¡å¼æ˜¯æ„å»ºèƒ½å¤Ÿè‡ªä¸»ä¼˜åŒ–å…¶è¾“å‡ºä»¥æ»¡è¶³ç‰¹å®šæ ‡å‡†çš„AIä»£ç†çš„é‡è¦æŠ€æœ¯ã€‚é€šè¿‡å»ºç«‹è¿­ä»£æ”¹è¿›å’Œè‡ªåŠ¨è¯„ä¼°çš„åé¦ˆå¾ªç¯ï¼Œä»£ç†å¯ä»¥ç”Ÿæˆè¶Šæ¥è¶Šç¬¦åˆé¢„å®šç›®æ ‡çš„é«˜è´¨é‡è§£å†³æ–¹æ¡ˆã€‚